{"name":"Metainspector","tagline":"Ruby gem for web scraping purposes.","body":"# MetaInspector [![Build Status](https://secure.travis-ci.org/jaimeiniesta/metainspector.png)](http://travis-ci.org/jaimeiniesta/metainspector) [![Dependency Status](https://gemnasium.com/jaimeiniesta/metainspector.png)](https://gemnasium.com/jaimeiniesta/metainspector)\r\n\r\nMetaInspector is a gem for web scraping purposes. You give it an URL, and it lets you easily get its title, links, images, charset, description, keywords, meta tags...\r\n\r\n## See it in action!\r\n\r\nYou can try MetaInspector live at this little demo: [https://metainspectordemo.herokuapp.com](https://metainspectordemo.herokuapp.com)\r\n\r\n## Installation\r\n\r\nInstall the gem from RubyGems:\r\n\r\n    gem install metainspector\r\n\r\nIf you're using it on a Rails application, just add it to your Gemfile and run `bundle install`\r\n\r\n    gem 'metainspector'\r\n\r\nThis gem is tested on Ruby versions 1.9.2, 1.9.3 and 2.0.0.\r\n\r\n## Usage\r\n\r\nInitialize a MetaInspector instance for an URL, like this:\r\n\r\n    page = MetaInspector.new('http://markupvalidator.com')\r\n\r\nIf you don't include the scheme on the URL, http:// will be used by default:\r\n\r\n    page = MetaInspector.new('markupvalidator.com')\r\n\r\nYou can also include the html which will be used as the document to scrape:\r\n\r\n    page = MetaInspector.new(\"http://markupvalidator.com\", :document => \"<html><head><title>Hello From Passed Html</title><a href='/hello'>Hello link</a></head><body></body></html>\")\r\n\r\n## Accessing scraped data\r\n\r\nThen you can see the scraped data like this:\r\n\r\n    page.url                # URL of the page\r\n    page.scheme             # Scheme of the page (http, https)\r\n    page.host               # Hostname of the page (like, markupvalidator.com, without the scheme)\r\n    page.root_url           # Root url (scheme + host, like http://markupvalidator.com/)\r\n    page.title              # title of the page, as string\r\n    page.links              # array of strings, with every link found on the page as an absolute URL\r\n    page.internal_links     # array of strings, with every internal link found on the page as an absolute URL\r\n    page.external_links     # array of strings, with every external link found on the page as an absolute URL\r\n    page.meta_description   # meta description, as string\r\n    page.description        # returns the meta description, or the first long paragraph if no meta description is found\r\n    page.meta_keywords      # meta keywords, as string\r\n    page.image              # Most relevant image, if defined with og:image\r\n    page.images             # array of strings, with every img found on the page as an absolute URL\r\n    page.feed               # Get rss or atom links in meta data fields as array\r\n    page.charset            # UTF-8\r\n    page.content_type       # content-type returned by the server when the url was requested\r\n\r\nMetaInspector uses dynamic methods for meta_tag discovery, so all these will work, and will be converted to a search of a meta tag by the corresponding name, and return its content attribute\r\n\r\n    page.meta_description   # <meta name=\"description\" content=\"...\" />\r\n    page.meta_keywords      # <meta name=\"keywords\" content=\"...\" />\r\n    page.meta_robots        # <meta name=\"robots\" content=\"...\" />\r\n    page.meta_generator     # <meta name=\"generator\" content=\"...\" />\r\n\r\nIt will also work for the meta tags of the form <meta http-equiv=\"name\" ... />, like the following:\r\n\r\n    page.meta_content_language  # <meta http-equiv=\"content-language\" content=\"...\" />\r\n    page.meta_Content_Type      # <meta http-equiv=\"Content-Type\" content=\"...\" />\r\n\r\nPlease notice that MetaInspector is case sensitive, so `page.meta_Content_Type` is not the same as `page.meta_content_type`\r\n\r\nYou can also access most of the scraped data as a hash:\r\n\r\n    page.to_hash  # { \"url\"   => \"http://markupvalidator.com\",\r\n                      \"title\" => \"MarkupValidator :: site-wide markup validation tool\", ... }\r\n\r\nThe original document is accessible from:\r\n\r\n    page.document         # A String with the contents of the HTML document\r\n\r\nAnd the full scraped document is accessible from:\r\n\r\n    page.parsed_document  # Nokogiri doc that you can use it to get any element from the page\r\n\r\n## Opengraph and Twitter card meta tags\r\n\r\nTwitter cards & Open graph tags make it possible for you to attach media experiences to Tweets & Facebook posts. Nowadays most of the content creators add these meta tags to headers to quickly identify content on the page. Sometimes these tags could be nested as well. For example when a site wants to provide information about primary image used on a page it could use\r\n\r\n    <meta name=\"og:image\" content=\"http://www.somedomain.com/assets/images/abc.jpeg\">\r\n    <meta name=\"og:image:width\" content=\"200\">\r\n    <meta name=\"twitter:image\" value=\"http://www.somedomain.com/assets/images/abc.jpeg\">\r\n    <meta property=\"twitter:image:width\" value=\"200\">\r\n\r\nAlso many sites use name & property, content & value attributes interchangeably. Using MetaInspector accessing this information is as easy as -\r\n\r\n    page.meta_og_image \r\n    page.meta_twitter_image_width \r\n\r\nNote that MetaInspector gives priority to content over value. In other words if there is a tag of the form\r\n\r\n    <meta property=\"og:something\" value=\"100\" content=\"real value\">\r\n    page.meta_og_something #=> \"real value\"\r\n\r\n## Options\r\n\r\n### Timeout\r\n\r\nBy default, MetaInspector times out after 20 seconds of waiting for a page to respond.\r\nYou can set a different timeout with a second parameter, like this:\r\n\r\n    page = MetaInspector.new('markupvalidator.com', :timeout => 5) # 5 seconds timeout\r\n\r\n### Redirections\r\n\r\nBy default, redirections from HTTP to HTTPS, and from HTTPS to HTTP are disallowed.\r\n\r\nHowever, you can tell MetaInspector to allow these redirections with the option `:allow_redirections`, like this:\r\n\r\n     # This will allow HTTP => HTTPS redirections\r\n     page = MetaInspector.new('facebook.com', :allow_redirections => :safe)\r\n\r\n     # And this will allow HTTP => HTTPS (\"safe\") and HTTPS => HTTP (\"unsafe\") redirections\r\n     page = MetaInspector.new('facebook.com', :allow_redirections => :all)\r\n\r\n### HTML Content Only\r\n\r\nMetaInspector will try to parse all URLs by default. If you want to raise an error when trying to parse a non-html URL (one that has a content-type different than text/html), you can state it like this:\r\n\r\n    page = MetaInspector.new('markupvalidator.com', :html_content_only => true)\r\n\r\nThis is useful when using MetaInspector on web spidering. Although on the initial URL you'll probably have an HTML URL, following links you may find yourself trying to parse non-html URLs.\r\n\r\n    page = MetaInspector.new('http://example.com/image.png')\r\n    page.title         # returns \"\"\r\n    page.content_type  # \"image/png\"\r\n    page.ok?           # true\r\n\r\n    page = MetaInspector.new('http://example.com/image.png', :html_content_only => true)\r\n    page.title         # returns nil\r\n    page.content_type  # \"image/png\"\r\n    page.ok?           # false\r\n    page.errors.first  # \"Scraping exception: The url provided contains image/png content instead of text/html content\"\r\n\r\n## Error handling\r\n\r\nYou can check if the page has been succesfully parsed with:\r\n\r\n    page.ok?     # Will return true if everything looks OK\r\n\r\nIn case there have been any errors, you can check them with:\r\n\r\n    page.errors  # Will return an array with the error messages\r\n\r\nIf you also want to see the errors on console, you can initialize MetaInspector with the verbose option like that:\r\n\r\n    page = MetaInspector.new('http://example.com', :verbose => true)\r\n\r\n## Examples\r\n\r\nYou can find some sample scripts on the samples folder, including a basic scraping and a spider that will follow external links using a queue. What follows is an example of use from irb:\r\n\r\n    $ irb\r\n    >> require 'metainspector'\r\n    => true\r\n\r\n    >> page = MetaInspector.new('http://markupvalidator.com')\r\n    => #<MetaInspector:0x11330c0 @url=\"http://markupvalidator.com\">\r\n\r\n    >> page.title\r\n    => \"MarkupValidator :: site-wide markup validation tool\"\r\n\r\n    >> page.meta_description\r\n    => \"Site-wide markup validation tool. Validate the markup of your whole site with just one click.\"\r\n\r\n    >> page.meta_keywords\r\n    => \"html, markup, validation, validator, tool, w3c, development, standards, free\"\r\n\r\n    >> page.links.size\r\n    => 15\r\n\r\n    >> page.links[4]\r\n    => \"/plans-and-pricing\"\r\n\r\n    >> page.document.class\r\n    => String\r\n\r\n    >> page.parsed_document.class\r\n    => Nokogiri::HTML::Document\r\n\r\n## ZOMG Fork! Thank you!\r\n\r\nYou're welcome to fork this project and send pull requests. Just remember to include specs.\r\n\r\nThanks to all the contributors:\r\n\r\n[https://github.com/jaimeiniesta/metainspector/graphs/contributors](https://github.com/jaimeiniesta/metainspector/graphs/contributors)\r\n\r\n## Related projects\r\n\r\n* [go-metainspector](https://github.com/fern4lvarez/go-metainspector), a port of MetaInspector for Go.\r\n* [Node-MetaInspector](https://github.com/gabceb/node-metainspector), a port of MetaInspector for Node.\r\n\r\n## License\r\nMetaInspector is released under the [MIT license](MIT-LICENSE).\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}